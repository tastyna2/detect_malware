import json
import os
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
from keras.models import Sequential
from keras.layers import Dense, Masking, Activation
from keras.layers.recurrent import LSTM
from keras.optimizers import Adam
from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.model_selection import GridSearchCV
from keras.callbacks import EarlyStopping
from sklearn.metrics import confusion_matrix

def load_hash_info(name, *args):
    h_array = {}
    max_length = {}
    l_array = np.empty(0)
    count = 0
    all = np.empty((0, 0))

    for n in name:
	h_array[n] = np.empty((0, 0))
	max_length[n] = 0

    for fname, element in args:
	j = 1

	with open(fname) as f:
	    for line in f:
		if j > 1000:
		    break
		data = json.loads(line)
		for n in name:
		    if data['hashes'][n] is None:
			data['hashes'][n] = ""
		    len_hash = len(data['hashes'][n])
		    hash_list = np.array([ord(c) - ord(' ') for c in data['hashes'][n]])
		    if len_hash > max_length[n]:
			h_array[n] = np.hstack([h_array[n], np.zeros((count, len_hash - max_length[n]))])
			max_length[n] = len_hash
		    elif len_hash < max_length[n]:
			hash_list = np.hstack([hash_list, np.zeros(max_length[n] - len_hash)])
		    h_array = np.vstack([h_array[n], hash_list])
		j += 1
		count += 1

	l_array = np.hstack([l_array, np.full(1000, element)])

    all = np.hstack([h_array[n] for n in name])

    return all, l_array

name_hashes = ["md5", "sha1", "sha256", "ssdeep", "imphash", "impfuzzy", "tlsh",
                "totalhash", "anymaster", "anymaster_v1_0_1", "endgame", "crits",
                "pehashng"]

fz = ['ssdeep', 'impfuzzy', 'totalhash', 'endgame']

if os.path.isfile('./fuzzy.npy'):
    X = np.load('fuzzy.npy')
    Y = np.hstack([np.ones(75000), np.zeros(75000)])
else:
    X, Y = load_hash_info(fz, ('ffridataset2020_malware.jsonl', 1), ('ffridataset2020_cleanware.jsonl', 0))
    np.save('fuzzy', X)

X = X.reshape(X.shape[0], X.shape[1], 1)

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, stratify=Y, random_state=0)

def build_model(num_hidden_units, activation):
    model = Sequential()
    model.add(LSTM(
	num_hidden_units,
	input_shape=(X.shape[1], 1),
	return_sequences=False))
    model.add(Dense(1, activation=activation))
    model.compile(loss="mean_squared_error", optimizer=Adam(lr=0.01), metrics=['accuracy'])
    return model

early_stopping = EarlyStopping(monitor='val_loss', mode='auto', patience=20)

params = {
    'num_hidden_units' :[128, 256, 512],
    'activation' :['relu', 'sigmoid']
}

model = KerasClassifier(build_fn = build_model, verbose=0)

grid = GridSearchCV(estimator=model, param_grid=params)
grid_result = grid.fit(X_train, Y_train, batch_size=300, epochs=100, validation_split=0.1, verbose=0, callbacks=[early_stopping])
print (grid_result.best_params_)
best = grid_result.best_estimator_
prob = best.predict_proba(X_test)[:, 1]

Y_pred = (prob > 0.5).astype(int)
print(confusion_matrix(Y_test, Y_pred))
Y_pred = (prob > 0.6).astype(int)
print(confusion_matrix(Y_test, Y_pred))
Y_pred = (prob > 0.7).astype(int)
print(confusion_matrix(Y_test, Y_pred))
Y_pred = (prob > 0.8).astype(int)
print(confusion_matrix(Y_test, Y_pred))
Y_pred = (prob > 0.9).astype(int)
print(confusion_matrix(Y_test, Y_pred))
