import json
import os
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import confusion_matrix

def load_hash_info(name, *args):
    max_length = {}
    h_array = {}
    l_array = np.empty(0)
    count = 0
    all = np.empty((0, 0))

    for n in name:
        h_array[n] = np.empty((0, 0))
        max_length[n] = 0

    for fname, element in args:
        j = 1

        with open(fname) as f:
            for line in f:
                if j > 100000:
                    break
                data = json.loads(line)
                for n in name:
                    if data['hashes'][n] is None:
                        data['hashes'][n] = ""
                    len_hash = len(data['hashes'][n])
                    hash_list = np.array([ord(c) - ord(' ') for c in data['hashes'][n]])
                    if len_hash > max_length[n]:
                        h_array[n] = np.hstack([h_array[n], np.zeros((count, len_hash - max_length[n]))])
                        max_length[n] = len_hash
                    elif len_hash < max_length[n]:
                        hash_list = np.hstack([hash_list, np.zeros(max_length[n] - len_hash)])
                    h_array[n] = np.vstack([h_array[n], hash_list])
                j += 1
                count += 1

        l_array = np.hstack([l_array, np.full(75000, element)])

    all = np.hstack(list(h_array.values()))

    return all, l_array

name_hashes = ['ssdeep', 'impfuzzy', 'endgame', 'totalhash']

if os.path.isfile('./fuzzy.npy'):
    X = np.load('fuzzy.npy')
    Y = np.hstack([np.ones(75000), np.zeros(75000)])
else:
    X, Y = load_hash_info(name_hashes, ('ffridataset2020_malware.jsonl', 1), ('ffridataset2020_cleanware.jsonl', 0))
    np.save('fuzzy', X)

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, stratify=Y, random_state=0)

parameters = {
    'n_estimators' :[300, 600],
    'max_depth' :[70, 90],
    'min_samples_leaf': [1],
    'min_samples_split': [2]
}

clf = GridSearchCV(estimator=RandomForestClassifier(), param_grid=parameters, cv=5, iid=False)
clf.fit(X_train, Y_train)

print("Best parameters set found on development set: %s" % clf.best_params_)

best = clf.best_estimator_
prob = best.predict_proba(X_test)[:, 1]
np.save('prob_fuzzy', prob)
Y_pred = (prob > 0.6).astype(int)
print(confusion_matrix(Y_test, Y_pred))
Y_pred = (prob > 0.7).astype(int)
print(confusion_matrix(Y_test, Y_pred))
Y_pred = (prob > 0.8).astype(int)
print(confusion_matrix(Y_test, Y_pred))
Y_pred = (prob > 0.9).astype(int)
print(confusion_matrix(Y_test, Y_pred))
