import math
import json
import os
import pickle
import numpy as np
from extract import PEFeatureExtractor
from make_array import load_surf_info
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from scipy.stats import spearmanr
from scipy.cluster import hierarchy
from collections import defaultdict
from sklearn.metrics import confusion_matrix
from importance import permutation_importance, low_fp_accuracy
import matplotlib.pyplot as plt

ext = PEFeatureExtractor()

if os.path.isfile('./all.npy'):
    X = np.load('all.npy')
else:
    if os.path.isfile('./surf.npy'):
        surf = np.load('surf.npy')
    else:
        surf = load_surf_info('surf', 'ffridataset2020_malware.jsonl', 'ffridataset2020_cleanware.jsonl')

    if os.path.isfile('./trid.npy'):
        trid = np.load('trid.npy')
    X = np.hstack([surf, trid])
    np.save('all', X)

Y = np.hstack([np.ones(75000), np.zeros(75000)])

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, stratify=Y, random_state=0)

if os.path.isfile('./compare.pickle'):
    with open('compare.pickle', mode='rb') as fp:
        best = pickle.load(fp)
else:
    parameters = {
        'n_estimators' :[700, 800],
        'max_depth' :[200, 300],
        'min_samples_leaf': [1],
        'min_samples_split': [2]
    }

    clf = GridSearchCV(estimator=RandomForestClassifier(), param_grid=parameters, cv=5, iid=False)
    clf.fit(X_train, Y_train)

    print("Best parameters set found on development set: %s" % clf.best_params_)

    best = clf.best_estimator_

    with open('compare.pickle', mode='wb') as fp:
        pickle.dump(best, fp)

if os.path.isfile('./cluster.txt'):
    with open('cluster.txt', mode='rb') as fp:
        cols = pickle.load(fp)
else:
    const_idx = np.where((X_train == X_train[0, :]).all(axis = 0))[0]
    X_train[0, const_idx] += 0.1
    corr = np.abs(spearmanr(X_train).correlation)
    corr_link = hierarchy.ward(corr)
    clstr = hierarchy.fcluster(corr_link, 1, criterion='distance')
    clstr_toid = defaultdict(list)
    for idx, clstr_id in enumerate(clstr):
        clstr_toid[clstr_id].append(idx)
    cols = [v if len(v) > 1 else v[0] for v in clstr_toid.values()]
    with open('cluster.txt', mode='wb') as fp:
        pickle.dump(cols, fp)

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, stratify=Y, random_state=0)

if os.path.isfile('./compare.npy'):
    ar_impt = np.load('compare.npy')
else:
    imptance = permutation_importance(best, X_train, Y_train, cols, n_repeats=10, random_state=0)
    idx_imptance = np.argsort(imptance.importances_mean)[::-1].reshape(-1, 1)
    sorted_imptance = np.sort(imptance.importances_mean)[::-1].reshape(-1, 1)
    ar_impt = np.hstack([idx_imptance, sorted_imptance])
    np.save('compare', ar_impt)

if os.path.isfile('./trid.txt'):
    with open('trid.txt', mode='rb') as fp:
        def_list = pickle.load(fp)
names = ext.name_strings()
names.extend(def_list)

if not os.path.isfile('./result_compare.txt'):
    result = [',\n'.join([names[idxx] for idxx in cols[int(idx)]]) + ' ' + str(impt)
        if isinstance(cols[int(idx)], list)
        else names[cols[int(idx)]] + ' ' + str(impt)
        for idx, impt in ar_impt]
    result_str = '\n'.join(result)

    with open('result_compare.txt', mode='w') as fp:
        fp.write(result_str)
'''
col_ix = ar_impt[:10, 0]
#val_ix = cols[int(col_ix)][0]
val_ix = np.array([cols[int(idx)][0] if isinstance(cols[int(idx)], list) else cols[int(idx)] for idx in col_ix])
num = 1
for vidx in val_ix:
    ftr = X[:, vidx]
    max_lg = math.ceil(np.log10(ftr.max()))
    if num == 6:
        bins = np.logspace(2, max_lg, max_lg - 1)
    elif num in [2, 4, 10]:
        bins = [0, 1]
    else:
        bins = np.hstack([0, np.logspace(0, max_lg, max_lg + 1)])
    ftr_m, ftr_c = np.split(ftr, 2)
    #ftrm_nonzero = ftr_m[np.where(ftr_m != 0)[0]]
    #ftrc_nonzero = ftr_c[np.where(ftr_c != 0)[0]]
    fig1 = plt.figure()
    ax1 = fig1.add_subplot(1,1,1)
    if num in [2, 4, 10]:
        left1, height1 = np.unique(ftr_m, return_counts=True)
        left2, height2 = np.unique(ftr_c, return_counts=True)
        width = 0.3
        ax1.bar(left1, height1, color='r', width=width, align='center', log=True)
        ax1.bar(left1+width, height2, color='b', width = width, align='center', log=True)
        ax1.set_xticks(left1 + width/2)
        ax1.set_xticklabels(left1)
        ax1.legend(['malware', 'clean'], loc='best')
    else:
        ax1.hist([ftr_m, ftr_c], bins=bins, color=['red', 'blue'], label=['malware', 'clean'], log=True)
        ax1.set_xscale('symlog')
        ax1.legend(loc='best')
    ax1.set_title(names[vidx] + ' histogram')
    ax1.set_xlabel(names[vidx])
    ax1.set_ylabel('freq')
    fig1.savefig('sample_' + str(num) + '.png')
    num += 1

'''
threshold = [10, 15, 20, 25, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 1000]
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, stratify=Y, random_state=0)

for v in threshold:
    col_idx = ar_impt[:v, 0]
    valid_idx = np.array([cols[int(idx)][0] if isinstance(cols[int(idx)], list) else cols[int(idx)] for idx in col_idx])
    S_train = X_train[:, valid_idx]
    S_test = X_test[:, valid_idx]

    parameters = {
        'n_estimators' :[700, 800],
        'max_depth' :[200, 300],
        'min_samples_leaf': [1],
        'min_samples_split': [2]
    }

    clf = GridSearchCV(estimator=RandomForestClassifier(), param_grid=parameters, cv=5, iid=False)
    clf.fit(S_train, Y_train)

    print("Best parameters set found on development set: %s" % clf.best_params_)

    best = clf.best_estimator_

    print('num of dim is ' + str(len(valid_idx)))
    Y_pred = best.predict(S_test)
    print(confusion_matrix(Y_test, Y_pred))
    prob = best.predict_proba(S_test)[:, 1]
    Y_pred = (prob > 0.6).astype(int)
    print(confusion_matrix(Y_test, Y_pred))
    Y_pred = (prob > 0.7).astype(int)
    print(confusion_matrix(Y_test, Y_pred))
    Y_pred = (prob > 0.8).astype(int)
    print(confusion_matrix(Y_test, Y_pred))
    Y_pred = (prob > 0.9).astype(int)
    print(confusion_matrix(Y_test, Y_pred))
    print(low_fp_accuracy(Y_test, prob, fp_rate=0.01))
    print(low_fp_accuracy(Y_test, prob))
